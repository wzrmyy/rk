### 考点1 多媒体压缩
---

#### 多媒体基础
多媒体技术主要是指文字、声音和图像等多种表达信息的形式和媒体，它强调多媒体信息的综合和集成处理。多媒体技术依赖于计算机的数字化和交互处理能力，它的关键技术是信息压缩技术和光盘存储技术，它的关键特性包括信息载体的多样性、交互性和集成性三个方面。

***多媒体计算机***

多媒体计算机的主要硬件除了常规的硬件如主机、软盘驱动器、硬盘驱动器、显示辑、网卡之外，还要有音频信息处理硬件、视频信息处理硬件及光盘驱动器等部分。
1. 音频卡用于处理音频信息，它可以把话筒、录音机、电子乐器等输入的声音信息进行模数转换、压缩等处理，也可以把经过计算机处理的数字化的声音信号通过还原(解压缩)、数模转换后用音箱播放出来，或者用录音设备记录下来。
2. 视频卡用来支持视频信号(如电视)的输入与输出。
3. 采集卡能将电视信号转换成计算机的数字信号，便于使用软件对转换后的数字信号进行剪辑处理、加工和色彩控制。还可将处理后的数字信号输出到录像带中。
4. 扫描仪将摄影作品、绘画作品或其他印刷材料上的文字和图像，甚至实物，扫描到计算机中，以便进行加工处理。
5. 光驱分为只读光驱和可读写光驱，可读写光驱又称刻录机。用于读取或存储大容量的多媒体信息。

***媒体的分类***

媒体可分为感觉媒体、表示媒体、表现媒体、存储媒体和传输媒体。
1. 感觉媒体：直接作用于人的感官，产生感觉(视、听、噢、味、触觉)的媒体，例如：语言、音乐、音响、图形、动画、数据、文字等都是感觉媒体。
2. 表示媒体：表示媒体是指用来表示感觉媒体的数据编码。如图像编码、文本编码和声音编码等。感觉媒体转换成表示媒体后，能够在计算机上进行加工处理和传输。
3. 表现媒体：表现媒体是指进行信息输入或输出的媒体。如键盘、鼠标、扫描仪、话筒、数码相机、摄像机为输入表现媒体，显示器、打印机、扬声器、投影仪为输出表现媒体。
4. 存储媒体：存储媒体是指用于存储表示媒体的物理实体。如硬盘、光盘等。
5. 传输媒体：传输媒体是指传输表示媒体(即数据编码)的物理实体。如：电缆、光缆等。

***存储媒体***

目前存储多媒体信息的介质除了磁盘外，主要是光盘。光盘存储器是利用激光聚在记录表面存储信息，根据激光束的反射光来读出信息。光盘存储器主要有CD、CD-ROM、DVD以及EOD等。
- CD-ROM的读取目前有三种方式：恒定角速度、恒定线速度和部分恒定角速度。CD-ROM非常适用于把大批量数据分发给大量的用户。与传统磁盘存储器相比，有以下优点：具有更大的容量，可靠性高，光盘的复制更简易，可更换，便于携带。其缺点是只渎，存取时间比较长。
- DVD-ROM技术类似于CD-ROM技术，但是可以提供更高的存储容量。DVD通过减小读取激光波长，增大光学物镜数值孔径来达到提高存储容量的目的。DVD可以分为单面单层、单面双层、双面单层和双面双层4种物理结构。

***多媒体集成语言***

同步化多媒体集成语言(Synchronized Multimedia Integration Language, SMIL)是由W3C(World Wide Web Consortium，万维网联盟)规定的多媒体操纵语言。SMIL与网页上用的HTML(Dynamic Hypertext Markup Language，动态超文本标记语言)的语法格式非常相似。

#### 压缩编码技术

***数据压缩概述***

数据之所以能够压缩，是因为基本原始信源的数据存在着很大的冗余度。一般来说，多媒体数据中存在以下种类的数据冗余。
1. 空间冗余(几何冗余)：一幅图像的背景及其景物中，在某点自身与其相邻的一些区域内，常存在有规则的相关性。
2. 时间冗余：对于电视动画类的图像，其序列中前后相邻的两幅图像之间呈现较强的相关性，这就反映为时间冗余。
3. 知觉冗余：知觉冗余是指那些处于人们听觉和视觉分辨率以下的视、音频信号，若在编码时舍去这种在感知门限以下的信号，虽然这会使恢复原信号产生一定的失真，但并不能为人们所感知，为此，此种超出人们感知能力部分的编码就称为知觉冗余。
4. 信息熵冗余：信息熵是指一组数据所携带的信息量。
5. 结构冗余：有些图像从大的区域上看存在着非常强的纹理结构。
6. 知识冗余：有许多图像的理解与某些基础知识有相当大的相关性。

数据压缩技术可以分为两大类：一类是无损压缩编码法，也称为冗余压缩法、熵编码法；另一类是有损压缩编码法，也称为熵压缩法。
1. 无损压缩法：去掉或减少了数据的冗余，这些冗余值可以重新插入到数据中，因此是可逆的，也是无失真压缩。它通常使用的是统计编码技术，包括哈夫曼编码、算术编码、行程编码等。它的压缩比较低，通常是2:1 ~ 5:1。
2. 有损压缩法：压缩了熵，会减少信息量，因此是不可逆的。它通常可以分为特征抽取和量化两大类。特征抽取包括基于模式的编码、分形编码等；量化包括零记忆量化、预测编码、直接映射、变换编码等方法。其中，预测编码和变换编码是最常见的方法。有损压缩能够达到较高的压缩比。对于声音可达4:1 ~ 8:1，对于动态的视频数据更是可高达100:1 ~ 400:1之多。

***数据压缩标准***

常用的数据压缩标准如下：
1. JPEG(Joint Photo rraphic Experts Group，联合图像专家组)。这是采用基于DCT(Discrete Cosine Transform，离散余弦变换)和可变长编码的算法。它的关键技术是变换编码、量化、差分编码、哈夫曼编码和行程编码等。
2. MPEG(动态图像专家组)是ISO(International Standards Organization, 国际标准化组织)制定和发布的视频、音频和数据的压缩标准。它的三大特点是兼容性好；压缩比高，可达200:1；数据的损失很小。
3. DVI(Digital Visual Interface，数字视频接口)。与MPEG-1相当，可达VHS(Video Home System，家用录像系统)水平，压缩后数据传输速率为l.5Mbps。为了扩大DVI的应用，Intel公司还推出了DVI算法的软件解码算法，可以将未压缩的数字视频文件压缩为原来的1/5 ~ 1/10。
4. H.261。它主要是针对在ISDN上实现电信会议应用，特别是面对面的可视电话和视频会议而设计的。
5. H.263。它主要是针对低带宽通信而设计的，它在低带宽下能够提供比H.261更好的图像效果。

#### 音频数据

音频技术用于实现计算机对声音的处理。

声音是一种由物体振动而产生的波。

当物体振动时，使周围的空气不断地压缩和放松，并向四周扩散，这就是声波。

人可以听到的声音频率范围是20Hz～20kHz。

***音频技术概述***

声音的三个要素是音强、音调和音色。

音强是声音的强度，取决于声间的振幅；音调与声音的频率有关，频率高则声音高，频率低则声音低；音色是由混入基音的泛音决定的，每个基音又都有固有的频率和不同音强的泛音，从而使得每个声音都具有特殊的音色效果。

音频技术包括音频采集(模拟音转换为计算机识别的数字信号)、语音解码/编码、文字一声音的转换、音乐合成、语音识别与理解、音频数据传输、音频视频同步、音频效果与编辑等。通常实现计算机语音输出有两种方法，分别是录音/重放和文字一声音转换。
1. 录音/重放：可获得高音质声音，并能够保留特定人或乐器的音色，但存储量会随时长呈线性增长。
2. 文字一声音转换：需预先建立语音参数数据库、发音规则库，然后通过计算机自动合成。虽然语音参数库的大小不会随时长增加而增大，但发音规则库的大小会随着语音质量的要求提高而增大。

语音合成技术可以分为发音参数合成、声音模型参数合成和波形编辑合成三种。合成策略包括频谱逼近和波形逼近。

***音频数据存储和传输***

在计算机中，要存储声音信息就必须对其数字化，通常需要经过采样、量化和编码三个步骤。

1. 采样：在模拟音频信号转换为数字音频信号时，每隔一小时间间隔就在模拟声音的波形上取一个幅度值。这个间隔时间称为采样频率。常用的采样频率为8kHz、11.025kHz、16kHz、22.05kHz(FM广播音质)、44.1kHz(CD音质)，48kHz(DVD音频或专业领域)，频率越高音质越好。它的选择是由尼奎斯特理论确定的，即采样频率不应低于声音信号最高频率的两倍。
2. 量化：用数字来表示音频幅度时，把某一幅度范围内的电压用一个数字表示，这个量化的级别通常用位(bit)来表示，位数越高则音质越好。
3. 编码：将声音数据写成计算机的数据格式。

在没有压缩之前，每秒钟所需的存储量可由下式估算出：
文件的字节数 = 采样频率(Hz) X 量化或采样位数(位) X 声道数 / 8

***音频数据格式***

主要的音频数据格式如下：
1. WAVE：扩展名为.wav，该格式记录声音的波形，故只要采样率高、采样字节长、机器速度快，利用该格式记录的声音文件能够和原声基本一致，质量非常高，但这样做的代价就是文件太大。
2. MOD(modification)：扩展名为.mod，该格式的文件里存放乐谱和乐曲使用的各种音色样本，具有回放效果明确、音色种类无限等优点。
3. Layer-3：扩展名为.mp3，现在最流行的声音文件格式，因其压缩率大，在网络可视电话通信方面应用广泛，但和CD唱片相比，音质不能令人非常满意。
4. Real Audio：扩展名为.ra，这种格式具有强大的压缩量和极小的失真使其在众多格式中脱颖而出。和MP3相同，它也是为了解决网络传输带宽资源而设计的，因此主要目标是压缩比和容错性，其次才是音质。
5. CD Audio：扩展名为.cda，唱片采用的格式，又叫“红皮书”格式，记录的是波形流，绝对地纯正、HIFI。但缺点是无法编辑，文件长度太大。
6. MIDI(Musical Instrument Digital Interface，乐器数字接口):扩展名.mid，作为音乐工业的数据通信标准，MIDI 能指挥各音乐设备运转，而且具有统一的格式标准，能够模仿原始乐器的各种演奏技巧甚至无法演奏的效果。
7. CMF(Creatiye Musical Format, Creative 音乐格式)：扩展名为.cmf, Creative公司的专用音乐格式,和MIDI差不多，只是音色和效果上有些特色，专用于FM声卡，但其兼容性也很差。

#### 颜色空间

本节主要介绍颜色的特征、颜色空间、图形和图像等。

***颜色属性***

视觉上的彩色可用亮度、色调和饱和度来描述，任意一种彩色光都是这3个特征的综合效果。

亮度是光作用于人眼时所引起的明亮程度的感觉，它与被观察物体的发光强度有关。由于其强度不同，看起来可能亮一些或暗一些。对同一物体照射的光越强，反射光也越强，感觉就越亮，而不同物体在相同照射情况下，反射性越强者看起来越亮。显然，如果彩色光的强度降至人看不清了，在亮度等级上它应与黑色对应；同样，如果其强度变得很大，那么亮度等级应与白色对应。此外，亮度感还与人类视觉系统的视敏功能有关，即使强度相间，颜色不同的光进入视觉系统，也可能会产生不同的亮度。

色调是当人眼看到一种或多种波长的光时所产生的彩色感觉，它反映颜色的种类，是决定颜色的基本特性。如红色、绿色等都是指色调。不透明物体的色调是指该物体在日光照射下，所反射的各光谱成分作用于人眼的综合效果；透明物体的色调则是透过该物体的光谱综合作用的效果。

饱和度是指颜色的纯度，即掺入白光的程度，或者说是指颜色的深浅程度。对于同一色调的彩色光，饱和度越深，颜色越鲜明，或者说越纯。例如，当红色加进白光之后冲淡为粉红色，其基本色调还是红色， 但饱和度降低；换句话说，淡色的饱和度比深色要低一些。饱和度还和亮度有关，因为若在饱和的彩色光中增加白光的成分， 由于增加了光能，因而变得更亮了，但是它的饱和度却降低了。如果在某色调的彩色光中掺入别的彩色光，会引起色调的变化，掺入白光仅引起饱和度的变化。

***颜色空间***

三原色原理是色度学中最基本的原理，是指自然界常见的各种颜色光， 都可由红(R)、绿(G)、蓝(B)3种颜色按不同比例相配制而成；同样，绝大多数颜色光也可以分解成红、绿、蓝三种色光。由于人眼对红、绿、蓝3种色光最敏感，因此，由这3种颜色相配制所得的彩色范围也最广，所以一般都选用这3种颜色作为基色。

***图形与图像***

在计算机科学中，图形和图像这两个概念是有区别的。

1. 图像也称为位图或点阵图，是指由输入设备捕捉的实际场景画面或以数字化形式存储的任意画面。图像都是由一些排成行列的像素组成的，在计算机中的存储格式有BMP(Bit Map Picture)、TIF(Tagged Image File Format)等，一般数据量较大。它除了可以表现真实的照片，也可以表现复杂绘画的某些细节，并具有灵活和富于创造力等特点。通常把一幅位图图像作为一个点矩阵处理，矩阵中的一个元素(像素)对应图像的一个点，相应的值表示该点的灰度或颜色等级。

2. 图形也称矢量图形，一般指用计算机绘制的画面，如直线、圆、圆弧、任意曲线和图表等。图形是用一个指令集合来描述的，这些指令用来描述图中线条的形状、位置、颜色等各种属性和参数。与图像文件不同，在图形文件中只记录生成图的算法和图上的某些特征点。

3. 分辨率。图形(图像)的主要指标有分辨率、点距、色彩数(灰度)。
    - 分辨率：可以分为屏幕分辨率和输出分辨率。屏幕分辨率是指每英寸的，点阵的行数或列数，这个数值越大，显示质量就越好。输出分辨率是指每英寸的像素点数，是衡量输出设备的精肢例p 数值越大，质盘越好。
    - 点距：指两个像索之间的距离，一般来说，分辨率越高，则像素点距的规格越小，显示效果越好。
    - 深度：图像深度确定彩色图像的每个像素可能有的颜色数，或者确定灰度图像的每个像素可能有的灰度级数。通常，图像深度也指存储每个像素所用的存储器位数，或者说用多少位存储器单元来表示，它也是用来度量图像分辨率的。每个像素颜色或灰度被量化后所占用的存储器位数越多，它能表达的颜色数目就越多，它的深度就越深。

4. 文件格式。常见的图形/图像文件有以下几种：
    - BMP: PC上最常用的位图格式，有压缩和不压缩两种形式，该格式可表现从2位到24位的色彩，分辨率也可从480×320dpi至1024×768dpi。
    - DIB(Device Independent Bitmap)：描述图像的能力基本与BMP相同，并且能运行于多种硬件平台，只是文件较大。
    - PCP(PC Paintbrush)：由Zsoft公司创建的一种经过压缩且节约磁盘空间的PC位图格式，它最高可表现24位图形(图像)。
    - DIF(Drawing Interchange Format): AutoCAD中的图形文件，它以ASCII(American Standard Code for Information Interchange，美国国家信息交换标准码)方式存储图形，表现图形在尺寸和大小方面十分精确。
    - WMF:Microsoft Windows图元文件，具有文件短小、图案造型化的特点。该类图形比较粗糙，并只能在Microsoft Office中调用编辑。
    - GIF(Graphics Interchange Format)：在各种平台的各种图形处理软件上均可处理的经过压缩的图形格式。缺点是存储色彩最高只能达到256 种，由于存在这种限制，除了Web网页还在使用它外，其他场合已很少使用了。
    - JPEG(Joint Photographics Expert Group)：可以大幅度地压缩图形文件的一种图形格式。对于同一幅画面，JPG格式存储的文件是其他类型图形文件的1/10到1/20，而且色彩数最高可达到24位，所以它应用相当广泛。
    - TIF：文件体积庞大，但存储信息量亦巨大，细微层次的信息较多，有利于原稿阶调与色彩的复制。该格式有压缩和非压缩两种形式，最高支持的色彩数可达16兆种。
    - EPS(Encapsulated PostScript)：用PostScript语言描述的ASCII图形文件，在Postscript图形打印机上能打印出高品质的图形(图像)，最高能表示32位图形(图像)。
    - PSD(Photoshop Standard):Photoshop中的标准文件格式，专门为Photoshop而优化的格式。
    - CDR(CorelDraw):CorelDraw的文件格式。另外，CDX是所有CorelDraw应用程序均能使用的图形(图像)文件，是发展成熟的CDR文件。
    - IFF(Image File Format)：用于大型超级图形处理平台，比如AMIGA机，好莱坞的特技大片多采用该图形格式处理。图形（图像）效果，包括色彩纹理等逼真再现原景。当然，诙格式耗用的内存外存等的计算机资源也十分巨大。
    - TGA(Tagged Graphic)：是True vision公司为其显示卡开发的图形文件格式，创建时期较早，最高色彩数可达32位。VDA, PIX, WIN, BPX, ICB等均属其旁系。
    - PCD(Photo CD)：由KODAK公司开发，其他软件系统对其只能读取。
    - MPT(Macintosh Paintbrush)或MAC:Macintosh机所使用的灰度图形(图像)模式，在Macintosh Paintbrush中使用，其分辨率只能是720×567dpi。
    - SWF(Flash):Flash是Adobe公司制定的一种应用于Internet 的动画格式，它是以矢量图作为基本的图像存储形式的。

#### 视频数据

动态图像，包括动画和视频信息，是连续渐变的静态图像或图形序列沿时间轴顺次更换显示，从而构成运动视感的媒体。当序列中每帧图像是由人工或计算机产生的图像时，常称为动画；当序列中每帧图像是通过实时摄取自然的景像或活动的对象时，常称为影像视频，或简称视频。

***视频文件格式***
1. Quicktime: Quicktime 是苹果公司的产品，采用了面向最终用户桌面系统的低成本、全运动视频的方式，在软件，压缩和解压缩中也开始采用这种方式。
2. AVI(Audio Video Interleaved，音频视频交错格式)：微软公司的视频格式，可在160×120的视窗中以15帧/秒回收视频并可带有8位的声音。也可以在VGA或超级VGA监视器上回收。
3. RealMedia: RealNetworks公司所制定的音频/视频压缩规范，采用了流的方式播放，使用户可以边下载边播放，而且其极高的影像压缩率虽然牺牲了一些画质与音质，但却能在较慢的网速上流畅地播放RealMedia格式的音乐和视频。
4. ASF(Advanced Streaming Format，高级流格式)：微软公司的文件压缩格式，由于它使用了MPEG.4 的压缩算法，所以压缩率和图像的质量都很不错。
5. WMV(Windows Media Video, Windows媒体视频)：一种独立于编码方式的在Internet上实时传播多媒体的技术标准，主要优点包括：本地或网络回放、可扩充的媒体类型、部件下载、可伸缩的媒体类型、流的优先级化、多语言支持、环境独立性、丰富的流间关系以及扩展性等。

***流媒体***

目前实现流媒体传输主要有两种方法：顺序流传输和实时流传输，它们分别适合于不同的应用场合。
1. 顺序流传输。顺序流传输采用顺序下载的方式进行传输，在下载的同时用户可以在线回放多媒体数据，但给定时刻只能观看已经下载的部分，不能跳到尚未下载的部分，也不能在传输期间根据网络状况对下载速度进行调整。由于标准的HTTP服务器就可以发送这种形式的流媒体，而不需要，其他特殊协议的支持，因此也常常被称作HTTP流式传输。顺序流式传输比较适合高质量的多媒体片段，如片头、片尾或者广告等。
2. 实时流传输。实时流式传输保证媒体信号带宽能够与当前网络状况相匹配，从而使得流媒体数据总是被实时地传送，因此特别适合现场事件。实时流传输支持随机访问，即用户可以通过快进或者后退操作来观看前面或者后面的内容。从理论上讲，实时流媒体一经播放就不会停顿，但事实上仍有可能发生周期性的暂停现象，尤其是在网络状况恶化时更是如此。与顺序流传输不同的是实时流传输需要用到特定的流媒体服务器，而且还需要特定网络协议的支持。

在流媒体传输中，使用的主要协议如下：
1. PNA(Progressive Networks Audio ，顺序网络音频)：Real专用的实时传输协议，它一般采用UDP 协议， 并占用7070端口，但当服务器在防火墙内且7070端口被挡，服务器把SmartingNetwork设为真时，则采用HTTP协议，并占用默认的80端口。
2. MMS(Microsoft Media Server Protocol ，微软的流媒体服务器协议)：连接Windows Media单播服务的默认方法。
3. RTP(Reai-time Transport Protocol，实时传输协议)：在Internet上处理多媒体数据流的一种网络协议，利用它能够在单播或者多播的网络环境中实现流媒体数据的实时传输。RTP通常使用UDP来进行多媒体数据的传输，但如果需要的话可以使用TCP或者ATM等其他协议，整个RTP协议由两个密切相关的部分组成：RTP数据协议和RTP控制协议。
4. RTCP(Real-time Transport Control Protocol，实时传输控制协议)：需要与RTP数据协议配合使用，当应用程序启动一个RTP会话时将同时占用两个端口，分别供RTP和RTCP使用。RTP本身并不能为按序传输数据包提供可靠的保证，也不提供流量控制和拥塞控制，这些都由RTCP来负责完成。通常RTCP会采用与RTP相同的分发机制，向会话中的所有成员周期性地发送控制信息，应用程序通过接收这些数据，从中我取会话参与者的相关资料，以及网络状况、分组丢失概率等反馈信息，从而能够对服务质盘进行控制或者对网络状况进行诊断。
5. RTSP(Real Time Streaming Protocol，实时流协议)：位于RTP和RTCP之上，其目的是希望通过IP网络有效地传输多媒体数据。作为一个应用层协议，RTSP提供了一个可供扩展的框架，它的意义在于使得实时流媒体数据的受控和点播变得可能。RTSP主要用来控制具有实时特性的数据发送，但它本身并不传输数据，而是必须依赖于下层传输协议所提供的某些服务。RTSP可以对流媒体提供诸如播放、暂停、快进等操作，它负责定义具体的控制消息、操作方法、状态码等，此外还描述了与RTP间的交互操作。








### 考点2 编码与存储技术
---